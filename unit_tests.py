#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæµ‹è¯•è„šæœ¬ï¼šå…¨é¢æµ‹è¯•Postgres MCPæ–°åŠŸèƒ½

æµ‹è¯•è¦†ç›–ï¼š
1. åŸºç¡€CRUDæ“ä½œ
2. å¤æ‚æŸ¥è¯¢æ¡ä»¶
3. æ‰¹é‡æ“ä½œ
4. ç´¢å¼•ç®¡ç†
5. æ¨¡å¼ç®¡ç†
6. é”™è¯¯åœºæ™¯å¤„ç†
7. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
8. æ‰©å±•åŠŸèƒ½æµ‹è¯•

è®¾è®¡åŸåˆ™ï¼šæµ‹è¯•å®Œæˆåæ•°æ®åº“çŠ¶æ€æ¢å¤åˆ°åˆå§‹çŠ¶æ€
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ srcè·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from postgres_mcp.sql import DbConnPool, SqlDriver
from postgres_mcp.database_operations import SimpleCrudOperations
from postgres_mcp.database_operations.simple_schema import SimpleSchemaOperations
from postgres_mcp.database_operations.data_types import (
    ColumnDefinition,
    DataType,
    IndexDefinition,
    QueryCondition,
    QueryOptions,
    TableDefinition,
)


class TestTracker:
    """æµ‹è¯•è¿½è¸ªå™¨ï¼Œè®°å½•åˆ›å»ºçš„èµ„æºä»¥ä¾¿æ¸…ç†"""
    
    def __init__(self):
        self.schemas_created = []
        self.tables_created = []
        self.indexes_created = []
        self.extensions_created = []
    
    def add_schema(self, schema_name: str):
        if schema_name not in self.schemas_created:
            self.schemas_created.append(schema_name)
    
    def add_table(self, table_name: str, schema: str = "public"):
        full_name = f"{schema}.{table_name}"
        if full_name not in self.tables_created:
            self.tables_created.append(full_name)
    
    def add_index(self, index_name: str):
        if index_name not in self.indexes_created:
            self.indexes_created.append(index_name)
    
    def add_extension(self, extension_name: str):
        if extension_name not in self.extensions_created:
            self.extensions_created.append(extension_name)


async def test_comprehensive_crud(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•å®Œæ•´çš„CRUDæ“ä½œ"""
    print("ğŸ§ª å¼€å§‹å…¨é¢CRUDæµ‹è¯•...")
    
    test_schema = "test_comprehensive"
    tracker.add_schema(test_schema)
    
    # 1. åˆ›å»ºæµ‹è¯•æ¨¡å¼
    print("\nğŸ“ åˆ›å»ºæµ‹è¯•æ¨¡å¼...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    print(f"   âœ… {result.message}")
    
    # 2. åˆ›å»ºå¤šä¸ªæµ‹è¯•è¡¨
    print("\nğŸ“‹ åˆ›å»ºå¤šä¸ªæµ‹è¯•è¡¨...")
    
    # ç”¨æˆ·è¡¨
    users_table = TableDefinition(
        name="users",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="username", data_type=DataType.VARCHAR, nullable=False, unique=True),
            ColumnDefinition(name="email", data_type=DataType.TEXT, nullable=False),
            ColumnDefinition(name="age", data_type=DataType.INTEGER, nullable=True),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP", nullable=False),
            ColumnDefinition(name="is_active", data_type=DataType.BOOLEAN, default="true", nullable=False),
        ]
    )
    
    result = await crud_ops.create_table(users_table)
    assert result.success, f"åˆ›å»ºç”¨æˆ·è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("users", test_schema)
    print(f"   âœ… ç”¨æˆ·è¡¨: {result.message}")
    
    # æ–‡ç« è¡¨
    posts_table = TableDefinition(
        name="posts",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="title", data_type=DataType.TEXT, nullable=False),
            ColumnDefinition(name="content", data_type=DataType.TEXT, nullable=True),
            ColumnDefinition(name="user_id", data_type=DataType.INTEGER, nullable=False),
            ColumnDefinition(name="metadata", data_type=DataType.JSONB, nullable=True),
            ColumnDefinition(name="published_at", data_type=DataType.TIMESTAMP, nullable=True),
            ColumnDefinition(name="view_count", data_type=DataType.INTEGER, default="0", nullable=False),
        ]
    )
    
    result = await crud_ops.create_table(posts_table)
    assert result.success, f"åˆ›å»ºæ–‡ç« è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("posts", test_schema)
    print(f"   âœ… æ–‡ç« è¡¨: {result.message}")
    
    # 3. æ’å…¥æµ‹è¯•æ•°æ®
    print("\nğŸ“ æ’å…¥æµ‹è¯•æ•°æ®...")
    
    # æ’å…¥ç”¨æˆ·æ•°æ®
    users_data = [
        {"username": "alice", "email": "alice@example.com", "age": 25},
        {"username": "bob", "email": "bob@example.com", "age": 30},
        {"username": "charlie", "email": "charlie@example.com", "age": None},
        {"username": "diana", "email": "diana@example.com", "age": 28, "is_active": False},
    ]
    
    result = await crud_ops.insert_records(
        table_name="users",
        data=users_data,
        schema=test_schema,
        returning_columns=["id", "username", "created_at"]
    )
    assert result.success, f"æ’å…¥ç”¨æˆ·æ•°æ®å¤±è´¥: {result.message}"
    assert len(result.returned_data) == 4, "è¿”å›çš„ç”¨æˆ·æ•°æ®æ•°é‡ä¸æ­£ç¡®"
    print(f"   âœ… æ’å…¥ç”¨æˆ·: {result.message}")
    
    # è·å–ç”¨æˆ·IDç”¨äºæ–‡ç« æ•°æ®
    user_ids = [row["id"] for row in result.returned_data]
    
    # æ’å…¥æ–‡ç« æ•°æ®
    posts_data = [
        {
            "title": "ç¬¬ä¸€ç¯‡æ–‡ç« ",
            "content": "è¿™æ˜¯Aliceçš„ç¬¬ä¸€ç¯‡æ–‡ç« å†…å®¹",
            "user_id": user_ids[0],
            "metadata": {"tags": ["tech", "AI"], "category": "æŠ€æœ¯"},
            "view_count": 100
        },
        {
            "title": "ç¬¬äºŒç¯‡æ–‡ç« ", 
            "content": "è¿™æ˜¯Bobçš„æ–‡ç« å†…å®¹",
            "user_id": user_ids[1],
            "metadata": {"tags": ["life"], "category": "ç”Ÿæ´»"},
            "published_at": "2025-01-01 12:00:00",
            "view_count": 50
        },
        {
            "title": "ç¬¬ä¸‰ç¯‡æ–‡ç« ",
            "content": "è¿™æ˜¯Charlieçš„æ–‡ç« ",
            "user_id": user_ids[2],
            "metadata": {"tags": ["travel"], "category": "æ—…è¡Œ"},
            "view_count": 25
        }
    ]
    
    result = await crud_ops.insert_records(
        table_name="posts",
        data=posts_data,
        schema=test_schema,
        returning_columns=["id", "title", "user_id"]
    )
    assert result.success, f"æ’å…¥æ–‡ç« æ•°æ®å¤±è´¥: {result.message}"
    assert len(result.returned_data) == 3, "è¿”å›çš„æ–‡ç« æ•°æ®æ•°é‡ä¸æ­£ç¡®"
    print(f"   âœ… æ’å…¥æ–‡ç« : {result.message}")
    
    # 4. å¤æ‚æŸ¥è¯¢æµ‹è¯•
    print("\nğŸ” å¤æ‚æŸ¥è¯¢æµ‹è¯•...")
    
    # åŸºç¡€æŸ¥è¯¢
    result = await crud_ops.query_records(
        table_name="users",
        schema=test_schema,
        columns=["id", "username", "email", "age"]
    )
    assert result.success and len(result.data) == 4, "åŸºç¡€ç”¨æˆ·æŸ¥è¯¢å¤±è´¥"
    print(f"   âœ… åŸºç¡€æŸ¥è¯¢: æŸ¥è¯¢åˆ° {len(result.data)} æ¡ç”¨æˆ·è®°å½•")
    
    # æ¡ä»¶æŸ¥è¯¢
    result = await crud_ops.query_records(
        table_name="users",
        schema=test_schema,
        columns=["username", "age"],
        conditions=[
            QueryCondition(column="age", operator=">", value=25)
        ]
    )
    assert result.success and len(result.data) == 2, "æ¡ä»¶æŸ¥è¯¢å¤±è´¥"
    print(f"   âœ… æ¡ä»¶æŸ¥è¯¢: å¹´é¾„>25çš„ç”¨æˆ· {len(result.data)} ä¸ª")
    
    # å¤æ‚æ¡ä»¶æŸ¥è¯¢
    result = await crud_ops.query_records(
        table_name="users",
        schema=test_schema,
        conditions=[
            QueryCondition(column="age", operator="IS NOT NULL", value=None),
            QueryCondition(column="is_active", operator="=", value=True, logical_operator="AND")
        ],
        options=QueryOptions(
            order_by=[{"column": "age", "direction": "DESC"}],
            limit=10
        )
    )
    print(f"   ğŸ” å¤æ‚æ¡ä»¶æŸ¥è¯¢ç»“æœ: æˆåŠŸ={result.success}, æ•°æ®æ¡æ•°={len(result.data) if result.success else 0}")
    if result.success and len(result.data) > 0:
        print(f"   âœ… å¤æ‚æ¡ä»¶æŸ¥è¯¢: æ´»è·ƒä¸”æœ‰å¹´é¾„çš„ç”¨æˆ· {len(result.data)} ä¸ª")
    else:
        print(f"   âš ï¸  å¤æ‚æ¡ä»¶æŸ¥è¯¢å¼‚å¸¸: {result.message if not result.success else 'æ— æ•°æ®'}")
    
    # JSONBæŸ¥è¯¢æµ‹è¯•
    result = await crud_ops.query_records(
        table_name="posts",
        schema=test_schema,
        columns=["title", "metadata"],
        options=QueryOptions(order_by=[{"column": "view_count", "direction": "DESC"}])
    )
    assert result.success and len(result.data) == 3, "JSONBæŸ¥è¯¢å¤±è´¥"
    print(f"   âœ… JSONBæŸ¥è¯¢: æŒ‰æµè§ˆé‡æ’åºçš„æ–‡ç«  {len(result.data)} ç¯‡")
    
    # 5. æ›´æ–°æ“ä½œæµ‹è¯•
    print("\nâœï¸  æ›´æ–°æ“ä½œæµ‹è¯•...")
    
    # å•æ¡æ›´æ–°
    result = await crud_ops.update_records(
        table_name="users",
        schema=test_schema,
        data={"age": 26},
        conditions=[
            QueryCondition(column="username", operator="=", value="alice")
        ],
        returning_columns=["id", "username", "age"]
    )
    assert result.success and result.affected_rows == 1, "å•æ¡æ›´æ–°å¤±è´¥"
    print(f"   âœ… å•æ¡æ›´æ–°: æ›´æ–°äº†Aliceçš„å¹´é¾„")
    
    # æ‰¹é‡æ›´æ–°
    result = await crud_ops.update_records(
        table_name="posts",
        schema=test_schema,
        data={"view_count": 200},
        conditions=[
            QueryCondition(column="view_count", operator="<", value=100)
        ],
        returning_columns=["id", "title", "view_count"]
    )
    assert result.success, "æ‰¹é‡æ›´æ–°å¤±è´¥"
    print(f"   âœ… æ‰¹é‡æ›´æ–°: æ›´æ–°äº† {result.affected_rows} ç¯‡æ–‡ç« çš„æµè§ˆé‡")
    
    # 6. ç´¢å¼•åˆ›å»ºæµ‹è¯•
    print("\nğŸ”— ç´¢å¼•åˆ›å»ºæµ‹è¯•...")
    
    # å•åˆ—ç´¢å¼•
    idx1 = IndexDefinition(
        name="idx_users_email",
        table_name="users",
        columns=["email"],
        index_type="btree",
        unique=True
    )
    result = await schema_ops.create_index(idx1, schema=test_schema)
    assert result.success, f"åˆ›å»ºé‚®ç®±å”¯ä¸€ç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_users_email")
    print(f"   âœ… å”¯ä¸€ç´¢å¼•: {result.message}")
    
    # å¤åˆç´¢å¼•
    idx2 = IndexDefinition(
        name="idx_posts_user_published",
        table_name="posts",
        columns=["user_id", "published_at"],
        index_type="btree"
    )
    result = await schema_ops.create_index(idx2, schema=test_schema)
    assert result.success, f"åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_posts_user_published")
    print(f"   âœ… å¤åˆç´¢å¼•: {result.message}")
    
    # éƒ¨åˆ†ç´¢å¼•
    idx3 = IndexDefinition(
        name="idx_posts_published",
        table_name="posts",
        columns=["published_at"],
        index_type="btree",
        partial_condition="published_at IS NOT NULL"
    )
    result = await schema_ops.create_index(idx3, schema=test_schema)
    assert result.success, f"åˆ›å»ºéƒ¨åˆ†ç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_posts_published")
    print(f"   âœ… éƒ¨åˆ†ç´¢å¼•: {result.message}")
    
    # 7. åˆ é™¤æ“ä½œæµ‹è¯•
    print("\nğŸ—‘ï¸  åˆ é™¤æ“ä½œæµ‹è¯•...")
    
    # åˆ é™¤ç‰¹å®šæ–‡ç« 
    result = await crud_ops.delete_records(
        table_name="posts",
        schema=test_schema,
        conditions=[
            QueryCondition(column="view_count", operator="=", value=200)
        ],
        returning_columns=["id", "title"]
    )
    assert result.success, "åˆ é™¤æ–‡ç« å¤±è´¥"
    deleted_count = result.affected_rows
    print(f"   âœ… æ¡ä»¶åˆ é™¤: åˆ é™¤äº† {deleted_count} ç¯‡æµè§ˆé‡ä¸º200çš„æ–‡ç« ")
    
    # éªŒè¯åˆ é™¤ç»“æœ
    result = await crud_ops.query_records(
        table_name="posts",
        schema=test_schema,
        columns=["id"]
    )
    remaining_posts = len(result.data) if result.success else 0
    expected_posts = 3 - deleted_count
    assert remaining_posts == expected_posts, f"åˆ é™¤åæ–‡ç« æ•°é‡ä¸æ­£ç¡®ï¼ŒæœŸæœ›{expected_posts}ï¼Œå®é™…{remaining_posts}"
    print(f"   âœ… éªŒè¯åˆ é™¤: å‰©ä½™æ–‡ç«  {remaining_posts} ç¯‡")
    
    print(f"âœ… å…¨é¢CRUDæµ‹è¯•å®Œæˆ")


async def test_error_scenarios(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations):
    """æµ‹è¯•é”™è¯¯åœºæ™¯å’Œè¾¹ç•Œæ¡ä»¶"""
    print("\nğŸš¨ é”™è¯¯åœºæ™¯æµ‹è¯•...")
    
    # æµ‹è¯•é‡å¤åˆ›å»ºæ¨¡å¼
    result = await schema_ops.create_schema("test_comprehensive")  # åº”è¯¥æˆåŠŸï¼ˆIF NOT EXISTSï¼‰
    assert result.success, "é‡å¤åˆ›å»ºæ¨¡å¼åº”è¯¥æˆåŠŸï¼ˆIF NOT EXISTSï¼‰"
    print("   âœ… é‡å¤åˆ›å»ºæ¨¡å¼æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ’å…¥åˆ°ä¸å­˜åœ¨çš„è¡¨
    try:
        result = await crud_ops.insert_records(
            table_name="nonexistent_table",
            data=[{"name": "test"}],
            schema="test_comprehensive"
        )
        assert not result.success, "æ’å…¥åˆ°ä¸å­˜åœ¨çš„è¡¨åº”è¯¥å¤±è´¥"
        print("   âœ… ä¸å­˜åœ¨è¡¨æ’å…¥æµ‹è¯•é€šè¿‡")
    except Exception:
        print("   âœ… ä¸å­˜åœ¨è¡¨æ’å…¥æµ‹è¯•é€šè¿‡ï¼ˆå¼‚å¸¸ï¼‰")
    
    # æµ‹è¯•ç©ºæ•°æ®æ’å…¥
    try:
        result = await crud_ops.insert_records(
            table_name="users",
            data=[],
            schema="test_comprehensive"
        )
        assert not result.success, "ç©ºæ•°æ®æ’å…¥åº”è¯¥å¤±è´¥"
        print("   âœ… ç©ºæ•°æ®æ’å…¥æµ‹è¯•é€šè¿‡")
    except Exception:
        print("   âœ… ç©ºæ•°æ®æ’å…¥æµ‹è¯•é€šè¿‡ï¼ˆå¼‚å¸¸ï¼‰")
    
    # æµ‹è¯•æ— æ•ˆæ¡ä»¶æŸ¥è¯¢
    result = await crud_ops.query_records(
        table_name="users",
        schema="test_comprehensive", 
        conditions=[
            QueryCondition(column="nonexistent_column", operator="=", value="test")
        ]
    )
    assert not result.success, "æ— æ•ˆåˆ—æŸ¥è¯¢åº”è¯¥å¤±è´¥"
    print("   âœ… æ— æ•ˆåˆ—æŸ¥è¯¢æµ‹è¯•é€šè¿‡")
    
    print("âœ… é”™è¯¯åœºæ™¯æµ‹è¯•å®Œæˆ")


async def test_vector_support_preparation():
    """æµ‹è¯•å‘é‡æ”¯æŒå‡†å¤‡ï¼ˆç¬¬äºŒé˜¶æ®µå¼€å§‹ï¼‰"""
    print("\nğŸ§¬ å‘é‡æ”¯æŒå‡†å¤‡æµ‹è¯•...")
    
    # è¿™é‡Œå°†ä¸ºç¬¬äºŒé˜¶æ®µçš„å‘é‡åŠŸèƒ½åšå‡†å¤‡
    # ç›®å‰åªæµ‹è¯•æ‰©å±•åˆ›å»ºå°è¯•
    print("   ğŸ¯ å‡†å¤‡è¿›å…¥å‘é‡æ•°æ®æ”¯æŒé˜¶æ®µ...")
    print("âœ… å‘é‡æ”¯æŒå‡†å¤‡å®Œæˆ")


async def cleanup_resources(schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æ¸…ç†æµ‹è¯•èµ„æºï¼Œæ¢å¤æ•°æ®åº“çŠ¶æ€"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•èµ„æº...")
    
    # æŒ‰ç›¸åé¡ºåºæ¸…ç†èµ„æº
    
    # 1. åˆ é™¤ç´¢å¼•
    for index_name in reversed(tracker.indexes_created):
        try:
            result = await schema_ops.drop_index(index_name)
            if result.success:
                print(f"   âœ… åˆ é™¤ç´¢å¼•: {index_name}")
            else:
                print(f"   âš ï¸  åˆ é™¤ç´¢å¼•å¤±è´¥: {index_name} - {result.message}")
        except Exception as e:
            print(f"   âš ï¸  åˆ é™¤ç´¢å¼•å¼‚å¸¸: {index_name} - {e}")
    
    # 2. åˆ é™¤è¡¨ï¼ˆæŒ‰schemaåˆ†ç»„ï¼‰
    for table_full_name in reversed(tracker.tables_created):
        try:
            schema_name, table_name = table_full_name.split(".", 1)
            result = await schema_ops.drop_table(table_name, schema_name)
            if result.success:
                print(f"   âœ… åˆ é™¤è¡¨: {table_full_name}")
            else:
                print(f"   âš ï¸  åˆ é™¤è¡¨å¤±è´¥: {table_full_name} - {result.message}")
        except Exception as e:
            print(f"   âš ï¸  åˆ é™¤è¡¨å¼‚å¸¸: {table_full_name} - {e}")
    
    # 3. åˆ é™¤æ¨¡å¼
    for schema_name in reversed(tracker.schemas_created):
        try:
            result = await schema_ops.drop_schema(schema_name, cascade=True)
            if result.success:
                print(f"   âœ… åˆ é™¤æ¨¡å¼: {schema_name}")
            else:
                print(f"   âš ï¸  åˆ é™¤æ¨¡å¼å¤±è´¥: {schema_name} - {result.message}")
        except Exception as e:
            print(f"   âš ï¸  åˆ é™¤æ¨¡å¼å¼‚å¸¸: {schema_name} - {e}")
    
    print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


async def test_table_schema_operations(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•è¡¨çº§æ“ä½œï¼šåˆ—ä¸¾ã€æŸ¥çœ‹ã€ä¿®æ”¹è¡¨ç»“æ„"""
    print("ğŸ—ï¸  å¼€å§‹è¡¨çº§æ“ä½œæµ‹è¯•...")
    
    test_schema = "test_table_ops"
    tracker.add_schema(test_schema)
    
    # 1. åˆ›å»ºæµ‹è¯•æ¨¡å¼
    print("\nğŸ“ åˆ›å»ºæµ‹è¯•æ¨¡å¼...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    print(f"   âœ… {result.message}")
    
    # 2. åˆ›å»ºæµ‹è¯•è¡¨ç”¨äºç»“æ„æ“ä½œ
    print("\nğŸ“‹ åˆ›å»ºæµ‹è¯•è¡¨...")
    test_table = TableDefinition(
        name="test_structure",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="name", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="description", data_type=DataType.TEXT, nullable=True),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP"),
        ]
    )
    
    result = await crud_ops.create_table(test_table)
    assert result.success, f"åˆ›å»ºæµ‹è¯•è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("test_structure", test_schema)
    print(f"   âœ… æµ‹è¯•è¡¨: {result.message}")
    
    # 3. æµ‹è¯•åˆ—ä¸¾æ¨¡å¼åŠŸèƒ½
    print("\nğŸ“ æµ‹è¯•åˆ—ä¸¾æ¨¡å¼...")
    try:
        sql_driver = crud_ops.sql_driver
        rows = await sql_driver.execute_query(
            """
            SELECT schema_name
            FROM information_schema.schemata
            WHERE schema_name = %s
            ORDER BY schema_name
            """,
            (test_schema,)
        )
        found_schemas = [row.cells["schema_name"] for row in rows] if rows else []
        assert test_schema in found_schemas, f"æœªæ‰¾åˆ°åˆ›å»ºçš„æ¨¡å¼ {test_schema}"
        print(f"   âœ… æˆåŠŸåˆ—ä¸¾æ¨¡å¼ï¼Œæ‰¾åˆ°: {found_schemas}")
    except Exception as e:
        print(f"   âŒ åˆ—ä¸¾æ¨¡å¼å¤±è´¥: {e}")
        raise
    
    # 4. æµ‹è¯•åˆ—ä¸¾è¡¨åŠŸèƒ½
    print("\nğŸ“Š æµ‹è¯•åˆ—ä¸¾è¡¨...")
    try:
        rows = await sql_driver.execute_query(
            """
            SELECT table_name, table_type
            FROM information_schema.tables
            WHERE table_schema = %s
            ORDER BY table_name
            """,
            (test_schema,)
        )
        found_tables = [(row.cells["table_name"], row.cells["table_type"]) for row in rows] if rows else []
        table_names = [name for name, _ in found_tables]
        assert "test_structure" in table_names, f"æœªæ‰¾åˆ°åˆ›å»ºçš„è¡¨ test_structure"
        print(f"   âœ… æˆåŠŸåˆ—ä¸¾è¡¨ï¼Œæ‰¾åˆ°: {table_names}")
    except Exception as e:
        print(f"   âŒ åˆ—ä¸¾è¡¨å¤±è´¥: {e}")
        raise
    
    # 5. æµ‹è¯•æŸ¥çœ‹è¡¨ç»“æ„è¯¦æƒ…
    print("\nğŸ” æµ‹è¯•æŸ¥çœ‹è¡¨ç»“æ„...")
    try:
        # æŸ¥çœ‹åˆ—ä¿¡æ¯
        rows = await sql_driver.execute_query(
            """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
            """,
            (test_schema, "test_structure")
        )
        columns_info = [
            {
                "column": row.cells["column_name"],
                "data_type": row.cells["data_type"],
                "nullable": row.cells["is_nullable"],
                "default": row.cells["column_default"]
            }
            for row in rows
        ] if rows else []
        
        expected_columns = ["id", "name", "description", "created_at"]
        found_columns = [col["column"] for col in columns_info]
        
        assert all(col in found_columns for col in expected_columns), f"è¡¨ç»“æ„ä¸å®Œæ•´ï¼ŒæœŸæœ›: {expected_columns}ï¼Œå®é™…: {found_columns}"
        print(f"   âœ… æˆåŠŸæŸ¥çœ‹è¡¨ç»“æ„ï¼Œåˆ—: {found_columns}")
        
        # éªŒè¯åˆ—çš„å…·ä½“å±æ€§
        id_column = next(col for col in columns_info if col["column"] == "id")
        assert id_column["nullable"] == "NO", "IDåˆ—åº”è¯¥ä¸å…è®¸NULL"
        assert "nextval" in (id_column["default"] or ""), "IDåˆ—åº”è¯¥æœ‰åºåˆ—é»˜è®¤å€¼"
        print(f"   âœ… IDåˆ—å±æ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"   âŒ æŸ¥çœ‹è¡¨ç»“æ„å¤±è´¥: {e}")
        raise
    
    # 6. æµ‹è¯•æŸ¥çœ‹çº¦æŸä¿¡æ¯
    print("\nğŸ”’ æµ‹è¯•æŸ¥çœ‹çº¦æŸä¿¡æ¯...")
    try:
        rows = await sql_driver.execute_query(
            """
            SELECT tc.constraint_name, tc.constraint_type, kcu.column_name
            FROM information_schema.table_constraints AS tc
            LEFT JOIN information_schema.key_column_usage AS kcu
              ON tc.constraint_name = kcu.constraint_name
             AND tc.table_schema = kcu.table_schema
            WHERE tc.table_schema = %s AND tc.table_name = %s
            """,
            (test_schema, "test_structure")
        )
        
        constraints = {}
        if rows:
            for row in rows:
                cname = row.cells["constraint_name"]
                ctype = row.cells["constraint_type"]
                col = row.cells["column_name"]
                
                if cname not in constraints:
                    constraints[cname] = {"type": ctype, "columns": []}
                if col:
                    constraints[cname]["columns"].append(col)
        
        # åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªä¸»é”®çº¦æŸ
        primary_keys = [name for name, info in constraints.items() if info["type"] == "PRIMARY KEY"]
        assert len(primary_keys) > 0, "è¡¨åº”è¯¥æœ‰ä¸»é”®çº¦æŸ"
        print(f"   âœ… çº¦æŸä¿¡æ¯æŸ¥çœ‹æˆåŠŸï¼Œçº¦æŸæ•°é‡: {len(constraints)}")
        
    except Exception as e:
        print(f"   âŒ æŸ¥çœ‹çº¦æŸä¿¡æ¯å¤±è´¥: {e}")
        raise
    
    # 7. æµ‹è¯•æŸ¥çœ‹ç´¢å¼•ä¿¡æ¯
    print("\nğŸ“‡ æµ‹è¯•æŸ¥çœ‹ç´¢å¼•ä¿¡æ¯...")
    try:
        rows = await sql_driver.execute_query(
            """
            SELECT indexname, indexdef
            FROM pg_indexes
            WHERE schemaname = %s AND tablename = %s
            """,
            (test_schema, "test_structure")
        )
        
        indexes = [{"name": row.cells["indexname"], "definition": row.cells["indexdef"]} for row in rows] if rows else []
        
        # ä¸»é”®ä¼šè‡ªåŠ¨åˆ›å»ºç´¢å¼•
        assert len(indexes) > 0, "è¡¨åº”è¯¥æœ‰ç´¢å¼•ï¼ˆè‡³å°‘æœ‰ä¸»é”®ç´¢å¼•ï¼‰"
        print(f"   âœ… ç´¢å¼•ä¿¡æ¯æŸ¥çœ‹æˆåŠŸï¼Œç´¢å¼•æ•°é‡: {len(indexes)}")
        
    except Exception as e:
        print(f"   âŒ æŸ¥çœ‹ç´¢å¼•ä¿¡æ¯å¤±è´¥: {e}")
        raise
    
    # 8. æµ‹è¯•æ·»åŠ æ–°åˆ—ï¼ˆæ¨¡æ‹ŸALTER TABLEï¼‰
    print("\nâ• æµ‹è¯•æ·»åŠ æ–°åˆ—...")
    try:
        # ä½¿ç”¨ç®€å•çš„SQLæ·»åŠ åˆ—
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."test_structure" ADD COLUMN status VARCHAR(20) DEFAULT \'active\''
        )
        
        # éªŒè¯æ–°åˆ—æ˜¯å¦æ·»åŠ æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s AND column_name = %s
            """,
            (test_schema, "test_structure", "status")
        )
        
        assert len(rows) > 0, "æ–°åˆ—æ·»åŠ å¤±è´¥"
        print(f"   âœ… æˆåŠŸæ·»åŠ æ–°åˆ— 'status'")
        
    except Exception as e:
        print(f"   âŒ æ·»åŠ æ–°åˆ—å¤±è´¥: {e}")
        raise
    
    # 9. æµ‹è¯•åˆ›å»ºç´¢å¼•
    print("\nğŸ” æµ‹è¯•åˆ›å»ºè‡ªå®šä¹‰ç´¢å¼•...")
    try:
        index_def = IndexDefinition(
            name="idx_test_structure_name",
            table_name="test_structure",
            columns=["name"],
            index_type="btree",
            unique=False
        )
        
        result = await schema_ops.create_index(index_def, test_schema)
        assert result.success, f"åˆ›å»ºç´¢å¼•å¤±è´¥: {result.message}"
        tracker.add_index("idx_test_structure_name")
        print(f"   âœ… ç´¢å¼•åˆ›å»º: {result.message}")
        
        # éªŒè¯ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT indexname
            FROM pg_indexes
            WHERE schemaname = %s AND tablename = %s AND indexname = %s
            """,
            (test_schema, "test_structure", "idx_test_structure_name")
        )
        
        assert len(rows) > 0, "ç´¢å¼•åˆ›å»ºåæœªæ‰¾åˆ°"
        print(f"   âœ… ç´¢å¼•éªŒè¯æˆåŠŸ")
        
    except Exception as e:
        print(f"   âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
        raise
    
    # 10. æµ‹è¯•è¡¨ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ æµ‹è¯•è¡¨ç»Ÿè®¡ä¿¡æ¯...")
    try:
        # æ’å…¥ä¸€äº›æµ‹è¯•æ•°æ®ç”¨äºç»Ÿè®¡
        test_data = [
            {"name": "æµ‹è¯•è®°å½•1", "description": "ç¬¬ä¸€æ¡è®°å½•", "status": "active"},
            {"name": "æµ‹è¯•è®°å½•2", "description": "ç¬¬äºŒæ¡è®°å½•", "status": "inactive"},
            {"name": "æµ‹è¯•è®°å½•3", "description": "ç¬¬ä¸‰æ¡è®°å½•", "status": "active"},
        ]
        
        result = await crud_ops.insert_records(
            table_name="test_structure",
            data=test_data,
            schema=test_schema
        )
        assert result.success, f"æ’å…¥æµ‹è¯•æ•°æ®å¤±è´¥: {result.message}"
        
        # æŸ¥è¯¢è¡¨è¡Œæ•°ç»Ÿè®¡
        rows = await sql_driver.execute_query(
            f"""
            SELECT COUNT(*) as total_rows
            FROM "{test_schema}"."test_structure"
            """
        )
        
        total_rows = rows[0].cells["total_rows"] if rows else 0
        assert total_rows == 3, f"è¡¨è¡Œæ•°ç»Ÿè®¡é”™è¯¯ï¼ŒæœŸæœ›3è¡Œï¼Œå®é™…{total_rows}è¡Œ"
        print(f"   âœ… è¡¨ç»Ÿè®¡ä¿¡æ¯: æ€»è¡Œæ•° {total_rows}")
        
        # æŸ¥è¯¢è¡¨å¤§å°ä¿¡æ¯
        rows = await sql_driver.execute_query(
            """
            SELECT 
                pg_size_pretty(pg_total_relation_size(%s)) as total_size,
                pg_size_pretty(pg_relation_size(%s)) as table_size
            """,
            (f"{test_schema}.test_structure", f"{test_schema}.test_structure")
        )
        
        if rows:
            size_info = rows[0].cells
            print(f"   âœ… è¡¨å¤§å°ä¿¡æ¯: æ€»å¤§å° {size_info['total_size']}, è¡¨å¤§å° {size_info['table_size']}")
        
    except Exception as e:
        print(f"   âŒ è¡¨ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢å¤±è´¥: {e}")
        raise
    
    print("âœ… è¡¨çº§æ“ä½œæµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def test_alter_table_operations(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•è¡¨ç»“æ„ä¿®æ”¹æ“ä½œ"""
    print("ğŸ”§ å¼€å§‹è¡¨ç»“æ„ä¿®æ”¹æµ‹è¯•...")
    
    test_schema = "test_alter_ops"
    tracker.add_schema(test_schema)
    
    # 1. åˆ›å»ºæµ‹è¯•æ¨¡å¼å’Œè¡¨
    print("\nğŸ“ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    print(f"   âœ… {result.message}")
    
    # åˆ›å»ºåŸºç¡€è¡¨
    alter_table = TableDefinition(
        name="alter_test",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="name", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="email", data_type=DataType.TEXT, nullable=True),
        ]
    )
    
    result = await crud_ops.create_table(alter_table)
    assert result.success, f"åˆ›å»ºæµ‹è¯•è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("alter_test", test_schema)
    print(f"   âœ… åŸºç¡€è¡¨åˆ›å»ºå®Œæˆ")
    
    sql_driver = crud_ops.sql_driver
    
    # 2. æµ‹è¯•æ·»åŠ åˆ—
    print("\nâ• æµ‹è¯•æ·»åŠ åˆ—...")
    try:
        # æ·»åŠ å¹´é¾„åˆ—
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" ADD COLUMN age INTEGER'
        )
        
        # æ·»åŠ å¸¦é»˜è®¤å€¼çš„åˆ—
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" ADD COLUMN status VARCHAR(20) DEFAULT \'active\' NOT NULL'
        )
        
        # éªŒè¯åˆ—æ˜¯å¦æ·»åŠ æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
            """,
            (test_schema, "alter_test")
        )
        
        columns = [row.cells["column_name"] for row in rows] if rows else []
        assert "age" in columns, "ageåˆ—æ·»åŠ å¤±è´¥"
        assert "status" in columns, "statusåˆ—æ·»åŠ å¤±è´¥"
        print(f"   âœ… åˆ—æ·»åŠ æˆåŠŸï¼Œå½“å‰åˆ—: {columns}")
        
    except Exception as e:
        print(f"   âŒ æ·»åŠ åˆ—å¤±è´¥: {e}")
        raise
    
    # 3. æµ‹è¯•ä¿®æ”¹åˆ—ç±»å‹
    print("\nğŸ”„ æµ‹è¯•ä¿®æ”¹åˆ—ç±»å‹...")
    try:
        # ä¿®æ”¹emailåˆ—ç±»å‹
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" ALTER COLUMN email TYPE VARCHAR(255)'
        )
        
        # éªŒè¯åˆ—ç±»å‹æ˜¯å¦ä¿®æ”¹æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT data_type, character_maximum_length
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s AND column_name = %s
            """,
            (test_schema, "alter_test", "email")
        )
        
        if rows:
            col_info = rows[0].cells
            assert col_info["data_type"] == "character varying", "emailåˆ—ç±»å‹ä¿®æ”¹å¤±è´¥"
            assert col_info["character_maximum_length"] == 255, "emailåˆ—é•¿åº¦è®¾ç½®å¤±è´¥"
            print(f"   âœ… åˆ—ç±»å‹ä¿®æ”¹æˆåŠŸ: {col_info}")
        
    except Exception as e:
        print(f"   âŒ ä¿®æ”¹åˆ—ç±»å‹å¤±è´¥: {e}")
        raise
    
    # 4. æµ‹è¯•æ·»åŠ çº¦æŸ
    print("\nğŸ”’ æµ‹è¯•æ·»åŠ çº¦æŸ...")
    try:
        # æ·»åŠ å”¯ä¸€çº¦æŸ
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" ADD CONSTRAINT uq_alter_test_email UNIQUE (email)'
        )
        
        # æ·»åŠ æ£€æŸ¥çº¦æŸ
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" ADD CONSTRAINT chk_alter_test_age CHECK (age IS NULL OR age >= 0)'
        )
        
        # éªŒè¯çº¦æŸæ˜¯å¦æ·»åŠ æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT constraint_name, constraint_type
            FROM information_schema.table_constraints
            WHERE table_schema = %s AND table_name = %s AND constraint_type IN ('UNIQUE', 'CHECK')
            """,
            (test_schema, "alter_test")
        )
        
        constraints = [(row.cells["constraint_name"], row.cells["constraint_type"]) for row in rows] if rows else []
        constraint_types = [ctype for _, ctype in constraints]
        
        assert "UNIQUE" in constraint_types, "å”¯ä¸€çº¦æŸæ·»åŠ å¤±è´¥"
        assert "CHECK" in constraint_types, "æ£€æŸ¥çº¦æŸæ·»åŠ å¤±è´¥"
        print(f"   âœ… çº¦æŸæ·»åŠ æˆåŠŸ: {constraints}")
        
    except Exception as e:
        print(f"   âŒ æ·»åŠ çº¦æŸå¤±è´¥: {e}")
        raise
    
    # 5. æµ‹è¯•åˆ›å»ºå¤åˆç´¢å¼•
    print("\nğŸ“‡ æµ‹è¯•åˆ›å»ºå¤åˆç´¢å¼•...")
    try:
        composite_index = IndexDefinition(
            name="idx_alter_test_name_status",
            table_name="alter_test",
            columns=["name", "status"],
            index_type="btree",
            unique=False
        )
        
        result = await schema_ops.create_index(composite_index, test_schema)
        assert result.success, f"åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥: {result.message}"
        tracker.add_index("idx_alter_test_name_status")
        print(f"   âœ… å¤åˆç´¢å¼•åˆ›å»º: {result.message}")
        
    except Exception as e:
        print(f"   âŒ åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥: {e}")
        raise
    
    # 6. æµ‹è¯•é‡å‘½ååˆ—ï¼ˆå¦‚æœæ”¯æŒï¼‰
    print("\nğŸ·ï¸  æµ‹è¯•é‡å‘½ååˆ—...")
    try:
        # PostgreSQLæ”¯æŒé‡å‘½ååˆ—
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" RENAME COLUMN email TO email_address'
        )
        
        # éªŒè¯åˆ—åæ˜¯å¦ä¿®æ”¹æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s AND column_name = %s
            """,
            (test_schema, "alter_test", "email_address")
        )
        
        assert len(rows) > 0, "åˆ—é‡å‘½åå¤±è´¥"
        print(f"   âœ… åˆ—é‡å‘½åæˆåŠŸ: email -> email_address")
        
    except Exception as e:
        print(f"   âŒ é‡å‘½ååˆ—å¤±è´¥: {e}")
        raise
    
    # 7. æµ‹è¯•åˆ é™¤åˆ—
    print("\nâ– æµ‹è¯•åˆ é™¤åˆ—...")
    try:
        # åˆ é™¤ageåˆ—
        await sql_driver.execute_query(
            f'ALTER TABLE "{test_schema}"."alter_test" DROP COLUMN age'
        )
        
        # éªŒè¯åˆ—æ˜¯å¦åˆ é™¤æˆåŠŸ
        rows = await sql_driver.execute_query(
            """
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s AND column_name = %s
            """,
            (test_schema, "alter_test", "age")
        )
        
        assert len(rows) == 0, "åˆ—åˆ é™¤å¤±è´¥ï¼Œageåˆ—ä»ç„¶å­˜åœ¨"
        print(f"   âœ… åˆ—åˆ é™¤æˆåŠŸ: ageåˆ—å·²ç§»é™¤")
        
    except Exception as e:
        print(f"   âŒ åˆ é™¤åˆ—å¤±è´¥: {e}")
        raise
    
    print("âœ… è¡¨ç»“æ„ä¿®æ”¹æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def test_mcp_tools_interface(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•MCPå·¥å…·æ¥å£åŠŸèƒ½"""
    print("ğŸ”§ å¼€å§‹MCPå·¥å…·æ¥å£æµ‹è¯•...")
    
    test_schema = "test_mcp_tools"
    tracker.add_schema(test_schema)
    
    # 1. å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
    print("\nğŸ“ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    test_table = TableDefinition(
        name="mcp_test_table",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="title", data_type=DataType.VARCHAR, nullable=False, unique=True),
            ColumnDefinition(name="content", data_type=DataType.TEXT, nullable=True),
            ColumnDefinition(name="metadata", data_type=DataType.JSONB, nullable=True),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP"),
        ]
    )
    
    result = await crud_ops.create_table(test_table)
    assert result.success, f"åˆ›å»ºæµ‹è¯•è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("mcp_test_table", test_schema)
    print(f"   âœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ")
    
    sql_driver = crud_ops.sql_driver
    
    # 2. æµ‹è¯•list_schemaså·¥å…·ï¼ˆæ¨¡æ‹ŸMCPè°ƒç”¨ï¼‰
    print("\nğŸ“ æµ‹è¯•list_schemaså·¥å…·...")
    try:
        # æ¨¡æ‹Ÿlist_schemas MCPå·¥å…·çš„å†…éƒ¨é€»è¾‘
        rows = await sql_driver.execute_query(
            """
            SELECT
                schema_name,
                schema_owner,
                CASE
                    WHEN schema_name LIKE 'pg_%' THEN 'System Schema'
                    WHEN schema_name = 'information_schema' THEN 'System Information Schema'
                    ELSE 'User Schema'
                END as schema_type
            FROM information_schema.schemata
            ORDER BY schema_type, schema_name
            """
        )
        schemas = [row.cells for row in rows] if rows else []
        
        # éªŒè¯æˆ‘ä»¬åˆ›å»ºçš„schemaæ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        schema_names = [schema["schema_name"] for schema in schemas]
        assert test_schema in schema_names, f"list_schemasæœªè¿”å›åˆ›å»ºçš„schema: {test_schema}"
        
        # éªŒè¯schemaç±»å‹åˆ†ç±»
        test_schema_info = next(schema for schema in schemas if schema["schema_name"] == test_schema)
        assert test_schema_info["schema_type"] == "User Schema", "æµ‹è¯•schemaåº”è¯¥è¢«åˆ†ç±»ä¸ºç”¨æˆ·schema"
        
        print(f"   âœ… list_schemaså·¥å…·æµ‹è¯•é€šè¿‡ï¼Œæ‰¾åˆ° {len(schemas)} ä¸ªschema")
        
    except Exception as e:
        print(f"   âŒ list_schemaså·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 3. æµ‹è¯•list_objectså·¥å…·ï¼ˆè¡¨ï¼‰
    print("\nğŸ“Š æµ‹è¯•list_objectså·¥å…·ï¼ˆè¡¨ï¼‰...")
    try:
        # æ¨¡æ‹Ÿlist_objects MCPå·¥å…·çš„å†…éƒ¨é€»è¾‘ï¼ˆè¡¨ç±»å‹ï¼‰
        rows = await sql_driver.execute_query(
            """
            SELECT table_schema, table_name, table_type
            FROM information_schema.tables
            WHERE table_schema = %s AND table_type = 'BASE TABLE'
            ORDER BY table_name
            """,
            (test_schema,)
        )
        
        objects = [
            {
                "schema": row.cells["table_schema"],
                "name": row.cells["table_name"],
                "type": row.cells["table_type"]
            }
            for row in rows
        ] if rows else []
        
        # éªŒè¯æˆ‘ä»¬åˆ›å»ºçš„è¡¨æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        table_names = [obj["name"] for obj in objects]
        assert "mcp_test_table" in table_names, f"list_objectsæœªè¿”å›åˆ›å»ºçš„è¡¨: mcp_test_table"
        
        print(f"   âœ… list_objectså·¥å…·ï¼ˆè¡¨ï¼‰æµ‹è¯•é€šè¿‡ï¼Œæ‰¾åˆ° {len(objects)} ä¸ªè¡¨")
        
    except Exception as e:
        print(f"   âŒ list_objectså·¥å…·ï¼ˆè¡¨ï¼‰æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 4. æµ‹è¯•list_objectså·¥å…·ï¼ˆåºåˆ—ï¼‰
    print("\nğŸ”¢ æµ‹è¯•list_objectså·¥å…·ï¼ˆåºåˆ—ï¼‰...")
    try:
        # æ¨¡æ‹Ÿlist_objects MCPå·¥å…·çš„å†…éƒ¨é€»è¾‘ï¼ˆåºåˆ—ç±»å‹ï¼‰
        rows = await sql_driver.execute_query(
            """
            SELECT sequence_schema, sequence_name, data_type
            FROM information_schema.sequences
            WHERE sequence_schema = %s
            ORDER BY sequence_name
            """,
            (test_schema,)
        )
        
        sequences = [
            {
                "schema": row.cells["sequence_schema"],
                "name": row.cells["sequence_name"],
                "data_type": row.cells["data_type"]
            }
            for row in rows
        ] if rows else []
        
        # SERIALç±»å‹ä¼šè‡ªåŠ¨åˆ›å»ºåºåˆ—
        assert len(sequences) > 0, "åº”è¯¥æœ‰è‡³å°‘ä¸€ä¸ªåºåˆ—ï¼ˆSERIALåˆ—åˆ›å»ºçš„ï¼‰"
        
        print(f"   âœ… list_objectså·¥å…·ï¼ˆåºåˆ—ï¼‰æµ‹è¯•é€šè¿‡ï¼Œæ‰¾åˆ° {len(sequences)} ä¸ªåºåˆ—")
        
    except Exception as e:
        print(f"   âŒ list_objectså·¥å…·ï¼ˆåºåˆ—ï¼‰æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 5. æµ‹è¯•get_object_detailså·¥å…·ï¼ˆè¡¨è¯¦æƒ…ï¼‰
    print("\nğŸ” æµ‹è¯•get_object_detailså·¥å…·ï¼ˆè¡¨è¯¦æƒ…ï¼‰...")
    try:
        # æ¨¡æ‹Ÿget_object_details MCPå·¥å…·çš„å†…éƒ¨é€»è¾‘
        
        # è·å–åˆ—ä¿¡æ¯
        col_rows = await sql_driver.execute_query(
            """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
            """,
            (test_schema, "mcp_test_table")
        )
        
        columns = [
            {
                "column": r.cells["column_name"],
                "data_type": r.cells["data_type"],
                "is_nullable": r.cells["is_nullable"],
                "default": r.cells["column_default"],
            }
            for r in col_rows
        ] if col_rows else []
        
        # è·å–çº¦æŸä¿¡æ¯
        con_rows = await sql_driver.execute_query(
            """
            SELECT tc.constraint_name, tc.constraint_type, kcu.column_name
            FROM information_schema.table_constraints AS tc
            LEFT JOIN information_schema.key_column_usage AS kcu
              ON tc.constraint_name = kcu.constraint_name
             AND tc.table_schema = kcu.table_schema
            WHERE tc.table_schema = %s AND tc.table_name = %s
            """,
            (test_schema, "mcp_test_table")
        )
        
        constraints = {}
        if con_rows:
            for row in con_rows:
                cname = row.cells["constraint_name"]
                ctype = row.cells["constraint_type"]
                col = row.cells["column_name"]
                
                if cname not in constraints:
                    constraints[cname] = {"type": ctype, "columns": []}
                if col:
                    constraints[cname]["columns"].append(col)
        
        constraints_list = [{"name": name, **data} for name, data in constraints.items()]
        
        # è·å–ç´¢å¼•ä¿¡æ¯
        idx_rows = await sql_driver.execute_query(
            """
            SELECT indexname, indexdef
            FROM pg_indexes
            WHERE schemaname = %s AND tablename = %s
            """,
            (test_schema, "mcp_test_table")
        )
        
        indexes = [
            {"name": r.cells["indexname"], "definition": r.cells["indexdef"]}
            for r in idx_rows
        ] if idx_rows else []
        
        # æ„å»ºå®Œæ•´çš„å¯¹è±¡è¯¦æƒ…
        result = {
            "basic": {"schema": test_schema, "name": "mcp_test_table", "type": "table"},
            "columns": columns,
            "constraints": constraints_list,
            "indexes": indexes,
        }
        
        # éªŒè¯ç»“æœ
        assert len(result["columns"]) == 5, f"åº”è¯¥æœ‰5åˆ—ï¼Œå®é™…æœ‰{len(result['columns'])}åˆ—"
        assert len(result["constraints"]) > 0, "åº”è¯¥æœ‰çº¦æŸï¼ˆè‡³å°‘æœ‰ä¸»é”®çº¦æŸï¼‰"
        assert len(result["indexes"]) > 0, "åº”è¯¥æœ‰ç´¢å¼•ï¼ˆè‡³å°‘æœ‰ä¸»é”®ç´¢å¼•ï¼‰"
        
        # éªŒè¯åˆ—å
        column_names = [col["column"] for col in result["columns"]]
        expected_columns = ["id", "title", "content", "metadata", "created_at"]
        assert all(col in column_names for col in expected_columns), f"åˆ—åä¸åŒ¹é…ï¼ŒæœŸæœ›: {expected_columns}ï¼Œå®é™…: {column_names}"
        
        print(f"   âœ… get_object_detailså·¥å…·ï¼ˆè¡¨è¯¦æƒ…ï¼‰æµ‹è¯•é€šè¿‡")
        print(f"       åˆ—æ•°: {len(result['columns'])}, çº¦æŸæ•°: {len(result['constraints'])}, ç´¢å¼•æ•°: {len(result['indexes'])}")
        
    except Exception as e:
        print(f"   âŒ get_object_detailså·¥å…·ï¼ˆè¡¨è¯¦æƒ…ï¼‰æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 6. æµ‹è¯•æ‰©å±•åˆ—ä¸¾åŠŸèƒ½
    print("\nğŸ§© æµ‹è¯•list_objectså·¥å…·ï¼ˆæ‰©å±•ï¼‰...")
    try:
        # æ¨¡æ‹Ÿlist_objects MCPå·¥å…·çš„å†…éƒ¨é€»è¾‘ï¼ˆæ‰©å±•ç±»å‹ï¼‰
        rows = await sql_driver.execute_query(
            """
            SELECT extname, extversion, extrelocatable
            FROM pg_extension
            ORDER BY extname
            """
        )
        
        extensions = [
            {
                "name": row.cells["extname"],
                "version": row.cells["extversion"],
                "relocatable": row.cells["extrelocatable"]
            }
            for row in rows
        ] if rows else []
        
        # åº”è¯¥è‡³å°‘æœ‰ä¸€äº›åŸºç¡€æ‰©å±•
        assert len(extensions) > 0, "åº”è¯¥æœ‰ä¸€äº›å·²å®‰è£…çš„æ‰©å±•"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰pgvectoræ‰©å±•ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
        extension_names = [ext["name"] for ext in extensions]
        has_pgvector = "vector" in extension_names
        
        print(f"   âœ… list_objectså·¥å…·ï¼ˆæ‰©å±•ï¼‰æµ‹è¯•é€šè¿‡ï¼Œæ‰¾åˆ° {len(extensions)} ä¸ªæ‰©å±•")
        if has_pgvector:
            print(f"       ğŸ¯ å‘ç°pgvectoræ‰©å±•ï¼Œæ”¯æŒå‘é‡æ“ä½œ")
        
    except Exception as e:
        print(f"   âŒ list_objectså·¥å…·ï¼ˆæ‰©å±•ï¼‰æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    # 7. æµ‹è¯•execute_sqlå…¼å®¹æ€§
    print("\nğŸ¯ æµ‹è¯•execute_sqlå…¼å®¹æ€§...")
    try:
        # æ’å…¥æµ‹è¯•æ•°æ®
        test_data = [
            {
                "title": "MCPæµ‹è¯•æ–‡ç« 1",
                "content": "è¿™æ˜¯é€šè¿‡MCPæ¥å£åˆ›å»ºçš„æµ‹è¯•æ–‡ç« ",
                "metadata": {"source": "mcp_test", "priority": 1}
            },
            {
                "title": "MCPæµ‹è¯•æ–‡ç« 2", 
                "content": "ç¬¬äºŒç¯‡æµ‹è¯•æ–‡ç« ",
                "metadata": {"source": "mcp_test", "priority": 2}
            }
        ]
        
        result = await crud_ops.insert_records(
            table_name="mcp_test_table",
            data=test_data,
            schema=test_schema,
            returning_columns=["id", "title", "created_at"]
        )
        assert result.success, f"æ’å…¥æµ‹è¯•æ•°æ®å¤±è´¥: {result.message}"
        
        # æŸ¥è¯¢æµ‹è¯•æ•°æ®
        result = await crud_ops.query_records(
            table_name="mcp_test_table",
            schema=test_schema,
            columns=["id", "title", "content", "metadata"],
                    conditions=[
            QueryCondition(column="metadata", operator="?", value="source")
        ]
        )
        assert result.success, f"æŸ¥è¯¢æµ‹è¯•æ•°æ®å¤±è´¥: {result.message}"
        assert len(result.data) == 2, f"åº”è¯¥æŸ¥è¯¢åˆ°2æ¡è®°å½•ï¼Œå®é™…{len(result.data)}æ¡"
        
        print(f"   âœ… execute_sqlå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼Œæ’å…¥å¹¶æŸ¥è¯¢åˆ° {len(result.data)} æ¡è®°å½•")
        
    except Exception as e:
        print(f"   âŒ execute_sqlå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    print("âœ… MCPå·¥å…·æ¥å£æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def test_advanced_queries(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•é«˜çº§æŸ¥è¯¢åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹é«˜çº§æŸ¥è¯¢æµ‹è¯•...")
    
    test_schema = "test_advanced_queries"
    tracker.add_schema(test_schema)
    
    # 1. å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
    print("\nğŸ“ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    products_table = TableDefinition(
        name="products",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="name", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="category", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="price", data_type=DataType.DECIMAL, nullable=False),
            ColumnDefinition(name="stock", data_type=DataType.INTEGER, nullable=False),
            ColumnDefinition(name="tags", data_type=DataType.JSONB, nullable=True),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP"),
        ]
    )
    
    result = await crud_ops.create_table(products_table)
    assert result.success, f"åˆ›å»ºäº§å“è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("products", test_schema)
    
    # æ’å…¥æµ‹è¯•æ•°æ®
    products_data = [
        {"name": "ç¬”è®°æœ¬ç”µè„‘", "category": "ç”µå­äº§å“", "price": 5999.99, "stock": 50, "tags": {"brand": "Apple", "color": "é“¶è‰²"}},
        {"name": "æ— çº¿é¼ æ ‡", "category": "ç”µå­äº§å“", "price": 199.99, "stock": 100, "tags": {"brand": "Logitech", "wireless": True}},
        {"name": "åŠå…¬æ¤…", "category": "å®¶å…·", "price": 899.99, "stock": 25, "tags": {"material": "çš®é©", "adjustable": True}},
        {"name": "å’–å•¡æ¯", "category": "å¨å…·", "price": 29.99, "stock": 200, "tags": {"material": "é™¶ç“·", "capacity": "300ml"}},
        {"name": "æœºæ¢°é”®ç›˜", "category": "ç”µå­äº§å“", "price": 599.99, "stock": 75, "tags": {"brand": "Cherry", "backlight": True}},
    ]
    
    result = await crud_ops.insert_records(
        table_name="products",
        data=products_data,
        schema=test_schema
    )
    assert result.success, f"æ’å…¥äº§å“æ•°æ®å¤±è´¥: {result.message}"
    print(f"   âœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆï¼Œæ’å…¥ {len(products_data)} æ¡äº§å“è®°å½•")
    
    # 2. æµ‹è¯•åŸºç¡€æ¡ä»¶æŸ¥è¯¢
    print("\nğŸ” æµ‹è¯•åŸºç¡€æ¡ä»¶æŸ¥è¯¢...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "category", "price"],
        conditions=[
            QueryCondition(column="category", operator="=", value="ç”µå­äº§å“")
        ]
    )
    assert result.success, f"åŸºç¡€æ¡ä»¶æŸ¥è¯¢å¤±è´¥: {result.message}"
    assert len(result.data) == 3, f"ç”µå­äº§å“åº”è¯¥æœ‰3ä»¶ï¼Œå®é™…{len(result.data)}ä»¶"
    print(f"   âœ… åŸºç¡€æ¡ä»¶æŸ¥è¯¢: æ‰¾åˆ° {len(result.data)} ä»¶ç”µå­äº§å“")
    
    # 3. æµ‹è¯•èŒƒå›´æŸ¥è¯¢
    print("\nğŸ“Š æµ‹è¯•èŒƒå›´æŸ¥è¯¢...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "price", "stock"],
        conditions=[
            QueryCondition(column="price", operator=">=", value=100),
            QueryCondition(column="price", operator="<=", value=1000, logical_operator="AND"),
            QueryCondition(column="stock", operator=">", value=30, logical_operator="AND")
        ]
    )
    assert result.success, f"èŒƒå›´æŸ¥è¯¢å¤±è´¥: {result.message}"
    print(f"   âœ… èŒƒå›´æŸ¥è¯¢: æ‰¾åˆ° {len(result.data)} ä»¶ç¬¦åˆä»·æ ¼å’Œåº“å­˜æ¡ä»¶çš„äº§å“")
    
    # 4. æµ‹è¯•INæŸ¥è¯¢
    print("\nğŸ“‹ æµ‹è¯•INæŸ¥è¯¢...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "category"],
        conditions=[
            QueryCondition(column="category", operator="IN", value=["ç”µå­äº§å“", "å®¶å…·"])
        ]
    )
    assert result.success, f"INæŸ¥è¯¢å¤±è´¥: {result.message}"
    assert len(result.data) >= 3, f"ç”µå­äº§å“å’Œå®¶å…·è‡³å°‘åº”è¯¥æœ‰4ä»¶ï¼Œå®é™…{len(result.data)}ä»¶"
    print(f"   âœ… INæŸ¥è¯¢: æ‰¾åˆ° {len(result.data)} ä»¶ç”µå­äº§å“å’Œå®¶å…·")
    
    # 5. æµ‹è¯•LIKEæ¨¡ç³ŠæŸ¥è¯¢
    print("\nğŸ”¤ æµ‹è¯•LIKEæ¨¡ç³ŠæŸ¥è¯¢...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "category"],
        conditions=[
            QueryCondition(column="name", operator="LIKE", value="%é”®%")
        ]
    )
    assert result.success, f"LIKEæŸ¥è¯¢å¤±è´¥: {result.message}"
    assert len(result.data) >= 1, f"åŒ…å«'é”®'çš„äº§å“è‡³å°‘åº”è¯¥æœ‰1ä»¶"
    print(f"   âœ… LIKEæŸ¥è¯¢: æ‰¾åˆ° {len(result.data)} ä»¶åç§°åŒ…å«'é”®'çš„äº§å“")
    
    # 6. æµ‹è¯•æ’åºåŠŸèƒ½
    print("\nâ¬†ï¸ æµ‹è¯•æ’åºåŠŸèƒ½...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "price"],
        options=QueryOptions(
            order_by=[{"column": "price", "direction": "DESC"}]
        )
    )
    assert result.success, f"æ’åºæŸ¥è¯¢å¤±è´¥: {result.message}"
    # éªŒè¯ä»·æ ¼æ˜¯é™åºæ’åˆ—
    prices = [float(row["price"]) for row in result.data]
    assert prices == sorted(prices, reverse=True), "ä»·æ ¼æ’åºä¸æ­£ç¡®"
    print(f"   âœ… æ’åºåŠŸèƒ½: æŒ‰ä»·æ ¼é™åºæ’åˆ— {len(result.data)} ä»¶äº§å“")
    
    # 7. æµ‹è¯•åˆ†é¡µåŠŸèƒ½
    print("\nğŸ“„ æµ‹è¯•åˆ†é¡µåŠŸèƒ½...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "price"],
        options=QueryOptions(
            limit=2,
            offset=1,
            order_by=[{"column": "id", "direction": "ASC"}]
        )
    )
    assert result.success, f"åˆ†é¡µæŸ¥è¯¢å¤±è´¥: {result.message}"
    assert len(result.data) == 2, f"åˆ†é¡µæŸ¥è¯¢åº”è¯¥è¿”å›2æ¡è®°å½•ï¼Œå®é™…{len(result.data)}æ¡"
    print(f"   âœ… åˆ†é¡µåŠŸèƒ½: è·³è¿‡1æ¡ï¼Œè¿”å› {len(result.data)} æ¡è®°å½•")
    
    # 8. æµ‹è¯•JSONæŸ¥è¯¢
    print("\nğŸ—‚ï¸ æµ‹è¯•JSONæŸ¥è¯¢...")
    result = await crud_ops.query_records(
        table_name="products",
        schema=test_schema,
        columns=["name", "tags"],
        conditions=[
            QueryCondition(column="tags", operator="?", value="brand")
        ]
    )
    assert result.success, f"JSONæŸ¥è¯¢å¤±è´¥: {result.message}"
    print(f"   âœ… JSONæŸ¥è¯¢: æ‰¾åˆ° {len(result.data)} ä»¶æœ‰å“ç‰Œæ ‡ç­¾çš„äº§å“")
    
    print("âœ… é«˜çº§æŸ¥è¯¢æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def test_batch_operations(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•æ‰¹é‡æ“ä½œåŠŸèƒ½"""
    print("ğŸ“¦ å¼€å§‹æ‰¹é‡æ“ä½œæµ‹è¯•...")
    
    test_schema = "test_batch_ops"
    tracker.add_schema(test_schema)
    
    # 1. å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
    print("\nğŸ“ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    batch_table = TableDefinition(
        name="batch_test",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="batch_id", data_type=DataType.INTEGER, nullable=False),
            ColumnDefinition(name="data", data_type=DataType.TEXT, nullable=False),
            ColumnDefinition(name="status", data_type=DataType.VARCHAR, default="pending", nullable=False),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP"),
        ]
    )
    
    result = await crud_ops.create_table(batch_table)
    assert result.success, f"åˆ›å»ºæ‰¹é‡æµ‹è¯•è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("batch_test", test_schema)
    print(f"   âœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ")
    
    # 2. æµ‹è¯•å¤§æ‰¹é‡æ’å…¥
    print("\nğŸ“¥ æµ‹è¯•å¤§æ‰¹é‡æ’å…¥...")
    batch_size = 100
    large_batch_data = [
        {
            "batch_id": i // 10,  # æ¯10æ¡è®°å½•ä¸€ä¸ªæ‰¹æ¬¡
            "data": f"æµ‹è¯•æ•°æ®_{i:04d}",
            "status": "pending" if i % 3 == 0 else "active"
        }
        for i in range(batch_size)
    ]
    
    result = await crud_ops.insert_records(
        table_name="batch_test",
        data=large_batch_data,
        schema=test_schema,
        returning_columns=["id", "batch_id"]
    )
    assert result.success, f"å¤§æ‰¹é‡æ’å…¥å¤±è´¥: {result.message}"
    assert result.affected_rows == batch_size, f"æ’å…¥è¡Œæ•°ä¸åŒ¹é…ï¼ŒæœŸæœ›{batch_size}ï¼Œå®é™…{result.affected_rows}"
    print(f"   âœ… å¤§æ‰¹é‡æ’å…¥: æˆåŠŸæ’å…¥ {result.affected_rows} æ¡è®°å½•")
    
    # 3. æµ‹è¯•æ‰¹é‡æ›´æ–°
    print("\nâœï¸ æµ‹è¯•æ‰¹é‡æ›´æ–°...")
    result = await crud_ops.update_records(
        table_name="batch_test",
        data={"status": "processed"},
        conditions=[
            QueryCondition(column="batch_id", operator="IN", value=[0, 1, 2])
        ],
        schema=test_schema
    )
    assert result.success, f"æ‰¹é‡æ›´æ–°å¤±è´¥: {result.message}"
    assert result.affected_rows > 0, "æ‰¹é‡æ›´æ–°åº”è¯¥å½±å“ä¸€äº›è¡Œ"
    print(f"   âœ… æ‰¹é‡æ›´æ–°: æ›´æ–°äº† {result.affected_rows} æ¡è®°å½•")
    
    # 4. æµ‹è¯•æ¡ä»¶æ‰¹é‡åˆ é™¤
    print("\nğŸ—‘ï¸ æµ‹è¯•æ¡ä»¶æ‰¹é‡åˆ é™¤...")
    # å…ˆæŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•æ•°
    result_query = await crud_ops.query_records(
        table_name="batch_test",
        schema=test_schema,
        columns=["COUNT(*) as count"],
        conditions=[
            QueryCondition(column="status", operator="=", value="pending")
        ]
    )
    pending_count = result_query.data[0]["count"] if result_query.success and result_query.data else 0
    
    # æ‰§è¡Œæ‰¹é‡åˆ é™¤
    result = await crud_ops.delete_records(
        table_name="batch_test",
        conditions=[
            QueryCondition(column="status", operator="=", value="pending")
        ],
        schema=test_schema
    )
    assert result.success, f"æ‰¹é‡åˆ é™¤å¤±è´¥: {result.message}"
    assert result.affected_rows == pending_count, f"åˆ é™¤è¡Œæ•°ä¸åŒ¹é…ï¼ŒæœŸæœ›{pending_count}ï¼Œå®é™…{result.affected_rows}"
    print(f"   âœ… æ‰¹é‡åˆ é™¤: åˆ é™¤äº† {result.affected_rows} æ¡pendingçŠ¶æ€çš„è®°å½•")
    
    # 5. æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½
    print("\nâš¡ æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½...")
    import time
    start_time = time.time()
    
    result = await crud_ops.query_records(
        table_name="batch_test",
        schema=test_schema,
        columns=["id", "batch_id", "data", "status"],
        options=QueryOptions(
            order_by=[{"column": "batch_id", "direction": "ASC"}]
        )
    )
    
    query_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    assert result.success, f"æ‰¹é‡æŸ¥è¯¢å¤±è´¥: {result.message}"
    print(f"   âœ… æ‰¹é‡æŸ¥è¯¢: æŸ¥è¯¢ {len(result.data)} æ¡è®°å½•è€—æ—¶ {query_time:.2f}ms")
    
    print("âœ… æ‰¹é‡æ“ä½œæµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def test_index_management(crud_ops: SimpleCrudOperations, schema_ops: SimpleSchemaOperations, tracker: TestTracker):
    """æµ‹è¯•ç´¢å¼•ç®¡ç†åŠŸèƒ½"""
    print("ğŸ“‡ å¼€å§‹ç´¢å¼•ç®¡ç†æµ‹è¯•...")
    
    test_schema = "test_index_mgmt"
    tracker.add_schema(test_schema)
    
    # 1. å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
    print("\nğŸ“ å‡†å¤‡æµ‹è¯•ç¯å¢ƒ...")
    result = await schema_ops.create_schema(test_schema)
    assert result.success, f"åˆ›å»ºæ¨¡å¼å¤±è´¥: {result.message}"
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    index_table = TableDefinition(
        name="index_test",
        schema=test_schema,
        columns=[
            ColumnDefinition(name="id", data_type=DataType.SERIAL, primary_key=True, nullable=False),
            ColumnDefinition(name="username", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="email", data_type=DataType.VARCHAR, nullable=False),
            ColumnDefinition(name="age", data_type=DataType.INTEGER, nullable=True),
            ColumnDefinition(name="city", data_type=DataType.VARCHAR, nullable=True),
            ColumnDefinition(name="metadata", data_type=DataType.JSONB, nullable=True),
            ColumnDefinition(name="created_at", data_type=DataType.TIMESTAMP, default="CURRENT_TIMESTAMP"),
        ]
    )
    
    result = await crud_ops.create_table(index_table)
    assert result.success, f"åˆ›å»ºç´¢å¼•æµ‹è¯•è¡¨å¤±è´¥: {result.message}"
    tracker.add_table("index_test", test_schema)
    print(f"   âœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ")
    
    sql_driver = crud_ops.sql_driver
    
    # 2. æµ‹è¯•åˆ›å»ºå•åˆ—ç´¢å¼•
    print("\nğŸ“„ æµ‹è¯•åˆ›å»ºå•åˆ—ç´¢å¼•...")
    username_index = IndexDefinition(
        name="idx_index_test_username",
        table_name="index_test",
        columns=["username"],
        index_type="btree",
        unique=False
    )
    
    result = await schema_ops.create_index(username_index, test_schema)
    assert result.success, f"åˆ›å»ºusernameç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_index_test_username")
    print(f"   âœ… å•åˆ—ç´¢å¼•: {result.message}")
    
    # 3. æµ‹è¯•åˆ›å»ºå”¯ä¸€ç´¢å¼•
    print("\nğŸ”‘ æµ‹è¯•åˆ›å»ºå”¯ä¸€ç´¢å¼•...")
    email_index = IndexDefinition(
        name="idx_index_test_email_unique",
        table_name="index_test",
        columns=["email"],
        index_type="btree",
        unique=True
    )
    
    result = await schema_ops.create_index(email_index, test_schema)
    assert result.success, f"åˆ›å»ºemailå”¯ä¸€ç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_index_test_email_unique")
    print(f"   âœ… å”¯ä¸€ç´¢å¼•: {result.message}")
    
    # 4. æµ‹è¯•åˆ›å»ºå¤åˆç´¢å¼•
    print("\nğŸ”— æµ‹è¯•åˆ›å»ºå¤åˆç´¢å¼•...")
    composite_index = IndexDefinition(
        name="idx_index_test_city_age",
        table_name="index_test",
        columns=["city", "age"],
        index_type="btree",
        unique=False
    )
    
    result = await schema_ops.create_index(composite_index, test_schema)
    assert result.success, f"åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_index_test_city_age")
    print(f"   âœ… å¤åˆç´¢å¼•: {result.message}")
    
    # 5. æµ‹è¯•åˆ›å»ºJSONç´¢å¼•
    print("\nğŸ—‚ï¸ æµ‹è¯•åˆ›å»ºJSONç´¢å¼•...")
    json_index = IndexDefinition(
        name="idx_index_test_metadata_gin",
        table_name="index_test",
        columns=["metadata"],
        index_type="gin",
        unique=False
    )
    
    result = await schema_ops.create_index(json_index, test_schema)
    assert result.success, f"åˆ›å»ºJSONç´¢å¼•å¤±è´¥: {result.message}"
    tracker.add_index("idx_index_test_metadata_gin")
    print(f"   âœ… JSONç´¢å¼•: {result.message}")
    
    # 6. æµ‹è¯•åˆ—ä¸¾ç´¢å¼•
    print("\nğŸ“‹ æµ‹è¯•åˆ—ä¸¾ç´¢å¼•...")
    rows = await sql_driver.execute_query(
        """
        SELECT indexname, indexdef
        FROM pg_indexes
        WHERE schemaname = %s AND tablename = %s
        ORDER BY indexname
        """,
        (test_schema, "index_test")
    )
    
    indexes = [
        {"name": row.cells["indexname"], "definition": row.cells["indexdef"]}
        for row in rows
    ] if rows else []
    
    # åº”è¯¥è‡³å°‘æœ‰ä¸»é”®ç´¢å¼• + æˆ‘ä»¬åˆ›å»ºçš„4ä¸ªç´¢å¼•
    assert len(indexes) >= 5, f"ç´¢å¼•æ•°é‡ä¸è¶³ï¼ŒæœŸæœ›è‡³å°‘5ä¸ªï¼Œå®é™…{len(indexes)}ä¸ª"
    
    index_names = [idx["name"] for idx in indexes]
    expected_indexes = [
        "idx_index_test_username",
        "idx_index_test_email_unique", 
        "idx_index_test_city_age",
        "idx_index_test_metadata_gin"
    ]
    
    for expected_idx in expected_indexes:
        assert expected_idx in index_names, f"ç´¢å¼• {expected_idx} æœªæ‰¾åˆ°"
    
    print(f"   âœ… ç´¢å¼•åˆ—ä¸¾: æ‰¾åˆ° {len(indexes)} ä¸ªç´¢å¼•")
    for idx in indexes:
        print(f"       - {idx['name']}")
    
    # 7. æµ‹è¯•åˆ é™¤ç´¢å¼•
    print("\nğŸ—‘ï¸ æµ‹è¯•åˆ é™¤ç´¢å¼•...")
    result = await schema_ops.drop_index("idx_index_test_metadata_gin")
    assert result.success, f"åˆ é™¤JSONç´¢å¼•å¤±è´¥: {result.message}"
    print(f"   âœ… ç´¢å¼•åˆ é™¤: {result.message}")
    
    # éªŒè¯ç´¢å¼•å·²åˆ é™¤
    rows = await sql_driver.execute_query(
        """
        SELECT indexname
        FROM pg_indexes
        WHERE schemaname = %s AND tablename = %s AND indexname = %s
        """,
        (test_schema, "index_test", "idx_index_test_metadata_gin")
    )
    
    assert len(rows) == 0, "JSONç´¢å¼•åˆ é™¤åä»ç„¶å­˜åœ¨"
    print(f"   âœ… ç´¢å¼•åˆ é™¤éªŒè¯é€šè¿‡")
    
    # 8. æµ‹è¯•ç´¢å¼•æ€§èƒ½å¯¹æ¯”
    print("\nâš¡ æµ‹è¯•ç´¢å¼•æ€§èƒ½å¯¹æ¯”...")
    # æ’å…¥æµ‹è¯•æ•°æ®
    test_data = [
        {
            "username": f"user_{i:04d}",
            "email": f"user_{i:04d}@example.com",
            "age": 20 + (i % 40),
            "city": ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³"][i % 4],
            "metadata": {"role": "user", "level": i % 5}
        }
        for i in range(1000)
    ]
    
    result = await crud_ops.insert_records(
        table_name="index_test",
        data=test_data,
        schema=test_schema
    )
    assert result.success, f"æ’å…¥æ€§èƒ½æµ‹è¯•æ•°æ®å¤±è´¥: {result.message}"
    
    # æµ‹è¯•ç´¢å¼•æŸ¥è¯¢æ€§èƒ½
    import time
    start_time = time.time()
    
    result = await crud_ops.query_records(
        table_name="index_test",
        schema=test_schema,
        columns=["id", "username", "email"],
        conditions=[
            QueryCondition(column="username", operator="=", value="user_0500")
        ]
    )
    
    query_time = (time.time() - start_time) * 1000
    assert result.success, f"ç´¢å¼•æŸ¥è¯¢å¤±è´¥: {result.message}"
    assert len(result.data) == 1, f"åº”è¯¥æ‰¾åˆ°1æ¡è®°å½•ï¼Œå®é™…{len(result.data)}æ¡"
    
    print(f"   âœ… ç´¢å¼•æŸ¥è¯¢æ€§èƒ½: åœ¨1000æ¡è®°å½•ä¸­æŸ¥è¯¢è€—æ—¶ {query_time:.2f}ms")
    
    print("âœ… ç´¢å¼•ç®¡ç†æµ‹è¯•å…¨éƒ¨å®Œæˆï¼")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Postgres MCPå¢å¼ºç‰ˆæµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # ä½¿ç”¨æä¾›çš„è¿œç¨‹æ•°æ®åº“è¿æ¥
    database_url = os.environ.get("DATABASE_URI", "postgresql://vipa:vipa_404@10.214.211.4:5432/remote_db")
    
    print(f"ğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
    print(f"   è¿æ¥URL: {database_url.replace('vipa_404', '***')}")
    
    tracker = TestTracker()
    
    try:
        # åˆå§‹åŒ–è¿æ¥
        print("\nğŸ”Œ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        db_pool = DbConnPool()
        await db_pool.pool_connect(database_url)
        sql_driver = SqlDriver(db_pool)
        
        # åˆå§‹åŒ–æ“ä½œç±»
        crud_ops = SimpleCrudOperations(sql_driver)
        schema_ops = SimpleSchemaOperations(sql_driver)
        
        print("   âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_comprehensive_crud(crud_ops, schema_ops, tracker)
        await test_table_schema_operations(crud_ops, schema_ops, tracker)
        await test_alter_table_operations(crud_ops, schema_ops, tracker)
        await test_mcp_tools_interface(crud_ops, schema_ops, tracker)
        await test_error_scenarios(crud_ops, schema_ops)
        await test_vector_support_preparation()
        await test_advanced_queries(crud_ops, schema_ops, tracker)
        await test_batch_operations(crud_ops, schema_ops, tracker)
        await test_index_management(crud_ops, schema_ops, tracker)
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼Œå¼€å§‹æ¸…ç†èµ„æº...")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†æµ‹è¯•èµ„æº
        try:
            if 'schema_ops' in locals():
                await cleanup_resources(schema_ops, tracker)
            if 'db_pool' in locals():
                await db_pool.close()
                print("   âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
        except Exception as e:
            print(f"   âš ï¸  æ¸…ç†èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    print("\nğŸ æµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæ¯•")
    print("=" * 60)


if __name__ == "__main__":
    success = asyncio.run(main()) 